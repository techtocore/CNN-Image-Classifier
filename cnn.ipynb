{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "from keras.layers import Activation, Dropout, Flatten, Dense \n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras import backend as K \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # used for loading images\n",
    "import numpy as np\n",
    "import os # used for navigating to image path\n",
    "import imageio # used for writing images\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_stat(DIR):\n",
    "  heights = []\n",
    "  widths = []\n",
    "  ct = 0\n",
    "  for catagory in os.listdir(DIR):\n",
    "    folder = os.path.join(DIR, catagory)\n",
    "    for img in os.listdir(folder):\n",
    "        #print(img)\n",
    "        path = os.path.join(folder, img)\n",
    "        data = np.array(Image.open(path)) #PIL Image library\n",
    "        heights.append(data.shape[0])\n",
    "        widths.append(data.shape[1])\n",
    "        ct += 1\n",
    "  avg_height = sum(heights) / len(heights)\n",
    "  avg_width = sum(widths) / len(widths)\n",
    "  print(\"Totoal images: \" + str(ct) + '\\n')\n",
    "  print(\"Average Height: \" + str(avg_height))\n",
    "  print(\"Max Height: \" + str(max(heights)))\n",
    "  print(\"Min Height: \" + str(min(heights)))\n",
    "  print('\\n')\n",
    "  print(\"Average Width: \" + str(avg_width))\n",
    "  print(\"Max Width: \" + str(max(widths)))\n",
    "  print(\"Min Width: \" + str(min(widths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totoal images: 450\n",
      "\n",
      "Average Height: 27.202222222222222\n",
      "Max Height: 206\n",
      "Min Height: 7\n",
      "\n",
      "\n",
      "Average Width: 27.586666666666666\n",
      "Max Width: 181\n",
      "Min Width: 10\n"
     ]
    }
   ],
   "source": [
    "size_stat('trainingData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 27, 27\n",
    "  \n",
    "train_data_dir = 'trainingData'\n",
    "validation_data_dir = 'validationData'\n",
    "nb_train_samples = 450 \n",
    "nb_validation_samples = 50\n",
    "epochs = 30\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first': \n",
    "    input_shape = (3, img_width, img_height) \n",
    "else: \n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator( rescale = 1. / 255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True) \n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1. / 255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 images belonging to 5 classes.\n",
      "450\n",
      "{'ஃ': 0, 'இ': 1, 'க': 2, 'த': 3, 'ப': 4}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_data_dir, \n",
    "                                                    target_size =(img_width, img_height), \n",
    "                                                    batch_size = batch_size, \n",
    "                                                    class_mode ='categorical') \n",
    "print(len(train_generator.filenames))\n",
    "print(train_generator.class_indices)\n",
    "print(len(train_generator.class_indices))\n",
    "class_dictionary = train_generator.class_indices\n",
    "num_classes = len(class_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "train_labels = train_generator.classes\n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir, \n",
    "                                                        target_size =(img_width, img_height), \n",
    "                                                        batch_size = batch_size, class_mode ='categorical') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels = validation_generator.classes\n",
    "validation_labels = to_categorical(validation_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2, 2), input_shape = input_shape)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss ='categorical_crossentropy', optimizer ='rmsprop', metrics =['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 32)        416       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               5538048   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 5,539,749\n",
      "Trainable params: 5,539,749\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "45/45 [==============================] - 9s 197ms/step - loss: 2.9604 - acc: 0.4867 - val_loss: 0.7637 - val_acc: 0.6800\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 7s 154ms/step - loss: 0.4733 - acc: 0.8378 - val_loss: 0.4524 - val_acc: 0.8000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 7s 161ms/step - loss: 0.3136 - acc: 0.8956 - val_loss: 0.2591 - val_acc: 0.9000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 7s 157ms/step - loss: 0.1938 - acc: 0.9378 - val_loss: 0.0876 - val_acc: 0.9800\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.1276 - acc: 0.9578 - val_loss: 0.0776 - val_acc: 0.9800\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 7s 152ms/step - loss: 0.1144 - acc: 0.9578 - val_loss: 0.2114 - val_acc: 0.9200\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 7s 157ms/step - loss: 0.0792 - acc: 0.9756 - val_loss: 0.0912 - val_acc: 0.9400\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 7s 156ms/step - loss: 0.0691 - acc: 0.9733 - val_loss: 0.1789 - val_acc: 0.9400\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 7s 151ms/step - loss: 0.0977 - acc: 0.9667 - val_loss: 0.1104 - val_acc: 0.9400\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 7s 151ms/step - loss: 0.0474 - acc: 0.9844 - val_loss: 0.1937 - val_acc: 0.9400\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 7s 150ms/step - loss: 0.0475 - acc: 0.9844 - val_loss: 0.1616 - val_acc: 0.9400\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 7s 152ms/step - loss: 0.0598 - acc: 0.9844 - val_loss: 0.1699 - val_acc: 0.9400\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 7s 151ms/step - loss: 0.0532 - acc: 0.9844 - val_loss: 0.0270 - val_acc: 1.0000\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 7s 149ms/step - loss: 0.0571 - acc: 0.9844 - val_loss: 0.0243 - val_acc: 0.9800\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.0168 - acc: 0.9956 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 9s 199ms/step - loss: 0.0303 - acc: 0.9933 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 7s 162ms/step - loss: 0.0314 - acc: 0.9844 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 6s 139ms/step - loss: 0.0157 - acc: 0.9933 - val_loss: 1.3123e-04 - val_acc: 1.0000\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 6s 140ms/step - loss: 0.0285 - acc: 0.9911 - val_loss: 4.0639e-04 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 8s 174ms/step - loss: 0.0196 - acc: 0.9933 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 0.0179 - acc: 0.9933 - val_loss: 0.0376 - val_acc: 0.9800\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 6s 138ms/step - loss: 0.0444 - acc: 0.9822 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "45/45 [==============================] - 6s 137ms/step - loss: 0.0110 - acc: 0.9956 - val_loss: 4.7587e-04 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 8.3452e-05 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.0245 - acc: 0.9933 - val_loss: 3.2928e-04 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "45/45 [==============================] - 6s 139ms/step - loss: 0.0251 - acc: 0.9889 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "45/45 [==============================] - 6s 137ms/step - loss: 0.0144 - acc: 0.9978 - val_loss: 7.0014e-04 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "45/45 [==============================] - 6s 141ms/step - loss: 0.0422 - acc: 0.9911 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "45/45 [==============================] - 6s 137ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 5.3080e-04 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "45/45 [==============================] - 6s 137ms/step - loss: 0.0249 - acc: 0.9933 - val_loss: 0.0022 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21dbc4d75c0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch = nb_train_samples // batch_size, \n",
    "                    epochs = epochs, \n",
    "                    validation_data = validation_generator, \n",
    "                    validation_steps = nb_validation_samples // batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 32)        416       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 26, 26, 50)        1650      \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 33800)             0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 50)                1690050   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 1,692,371\n",
      "Trainable params: 1,692,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, (2, 2), input_shape = input_shape)) \n",
    "model1.add(Activation('relu')) \n",
    "model1.add(Dense(50, activation='relu'))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(50, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(num_classes, activation='softmax'))\n",
    "model1.compile(loss ='categorical_crossentropy', optimizer ='rmsprop', metrics =['accuracy']) \n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 4s 78ms/step - loss: 1.6264 - acc: 0.4178 - val_loss: 1.1358 - val_acc: 0.5800\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 3s 60ms/step - loss: 0.9448 - acc: 0.6222 - val_loss: 0.6914 - val_acc: 0.7200\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 0.7744 - acc: 0.7022 - val_loss: 0.4348 - val_acc: 0.8600\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 0.5734 - acc: 0.7756 - val_loss: 0.2495 - val_acc: 0.9000\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 0.5220 - acc: 0.7889 - val_loss: 0.1899 - val_acc: 0.9800\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 3s 56ms/step - loss: 0.4412 - acc: 0.8044 - val_loss: 0.0771 - val_acc: 0.9800\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 2s 55ms/step - loss: 0.3605 - acc: 0.8356 - val_loss: 0.2200 - val_acc: 0.9200\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 3s 56ms/step - loss: 0.3703 - acc: 0.8467 - val_loss: 0.2043 - val_acc: 0.8800\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 3s 56ms/step - loss: 0.2810 - acc: 0.8911 - val_loss: 0.1473 - val_acc: 0.9400\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 3s 56ms/step - loss: 0.2947 - acc: 0.8956 - val_loss: 0.6152 - val_acc: 0.7800\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 2s 55ms/step - loss: 0.3002 - acc: 0.8844 - val_loss: 0.1554 - val_acc: 0.9200\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 3s 56ms/step - loss: 0.2097 - acc: 0.9222 - val_loss: 0.5540 - val_acc: 0.8600\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 0.1652 - acc: 0.9333 - val_loss: 0.0596 - val_acc: 0.9600\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 0.2197 - acc: 0.9200 - val_loss: 0.1031 - val_acc: 0.9600\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 2s 55ms/step - loss: 0.2287 - acc: 0.9311 - val_loss: 0.0315 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 3s 56ms/step - loss: 0.2105 - acc: 0.9111 - val_loss: 0.0536 - val_acc: 0.9800\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 0.2139 - acc: 0.9089 - val_loss: 0.0373 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 3s 56ms/step - loss: 0.1643 - acc: 0.9311 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 0.1501 - acc: 0.9444 - val_loss: 0.0602 - val_acc: 0.9600\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 2s 56ms/step - loss: 0.1830 - acc: 0.9267 - val_loss: 0.1575 - val_acc: 0.9400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21dc0254c18>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit_generator(train_generator, \n",
    "                    steps_per_epoch = nb_train_samples // batch_size, \n",
    "                    epochs = 20, \n",
    "                    validation_data = validation_generator, \n",
    "                    validation_steps = nb_validation_samples // batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading and preprocessing image...\n"
     ]
    }
   ],
   "source": [
    "    image_path = 'pa.jpeg'\n",
    "\n",
    "    orig = cv2.imread(image_path)\n",
    "\n",
    "    print(\"[INFO] loading and preprocessing image...\")\n",
    "    image = load_img(image_path, target_size=(27, 27))\n",
    "    image = img_to_array(image)\n",
    "\n",
    "    # important! otherwise the predictions will be '0'\n",
    "    image = image / 255\n",
    "\n",
    "    image = np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.1605244e-10 1.6281776e-05 1.4319778e-09 5.8122951e-09 9.9998367e-01]]\n",
      "Image ID: 4, Label: ப\n"
     ]
    }
   ],
   "source": [
    "#prediction = model.predict_classes(image)\n",
    "#print(prediction)\n",
    "class_predicted = model.predict_classes(image)\n",
    "\n",
    "probabilities = model.predict_proba(image)\n",
    "\n",
    "print(probabilities)\n",
    "\n",
    "inID = class_predicted[0]\n",
    "\n",
    "inv_map = {v: k for k, v in class_dictionary.items()}\n",
    "\n",
    "label = inv_map[inID]\n",
    "\n",
    "# get the prediction label\n",
    "print(\"Image ID: {}, Label: {}\".format(inID, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.0039211e-05 1.1486738e-07 2.4560780e-08 1.0766754e-03 9.9889320e-01]]\n",
      "Image ID: 4, Label: ப\n"
     ]
    }
   ],
   "source": [
    "#prediction = model.predict_classes(image)\n",
    "#print(prediction)\n",
    "class_predicted = model1.predict_classes(image)\n",
    "\n",
    "probabilities = model1.predict_proba(image)\n",
    "\n",
    "print(probabilities)\n",
    "\n",
    "inID = class_predicted[0]\n",
    "\n",
    "inv_map = {v: k for k, v in class_dictionary.items()}\n",
    "\n",
    "label = inv_map[inID]\n",
    "\n",
    "# get the prediction label\n",
    "print(\"Image ID: {}, Label: {}\".format(inID, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
